# Performance — Ingestor (benchmarks)

## Goal
Measure ingestion performance on a large CSV, identify bottlenecks, and document improvements with proof.

## Dataset (local only)
- File: `data/perf/events_1m.csv` (1,000,000 rows, ~78MB)
- Generated by: `scripts/gen_events_csv.py`
- IMPORTANT: do NOT commit `data/perf/` outputs, `.jsonl`, or `.pstats` files.

## Why this benchmark command
On older commits, the `ingest` CLI entrypoint may not exist, and `python -m ingestor.cli` may not call `main()`.
So we call `main()` explicitly (robust across commits):

time PYTHONPATH=services/ingestor/src uv run python -c "from ingestor.cli import main; raise SystemExit(main([...]))"

## Benchmarks (real end-to-end time)
We compare **shell `time ... total`**, which measures the full pipeline (parse + write + overhead),
not the internal `time=...` printed by the program (which may time only part of the pipeline).

### Baseline
- Commit: `e528f6b` (feat: add CLI options max-errors and show-errors)
- Command:
time PYTHONPATH=services/ingestor/src uv run python -c "from ingestor.cli import main; raise SystemExit(main(['--input','data/perf/events_1m.csv','--output','/tmp/events_baseline.jsonl','--max-errors','1']))"
- Output:
- Program printed: `[OK] ... time=2.837s ...`
- Shell total: `14.112 total`

### Optimized
- Commit: `121182a` (perf: compact JSON output + benchmark script)
- Command:
time PYTHONPATH=services/ingestor/src uv run python -c "from ingestor.cli import main; raise SystemExit(main(['--input','data/perf/events_1m.csv','--output','/tmp/events_opt2.jsonl','--max-errors','1']))"
- Output:
- Program printed: `[OK] ... time=2.796s ...`
- Shell total: `6.362 total`

## Results summary
- Baseline total: **14.112s**
- Optimized total: **6.362s**
- Speedup: **~2.22× faster**
- Reduction: **~55% less total runtime**

## Interpretation
- The internal `time=~2.8s` stayed similar across commits → the main improvement is not in CSV parsing itself.
- The big gain comes from work outside the timed block (most likely JSONL writing / object conversion).
- Next profiling focus: `json.loads`, `json.dumps`, and write path.

## Compact JSON A/B test (same code, only separators differ)
To isolate the effect of `json.dumps(..., separators=(",", ":"))`, we ran the same code twice:

Commands:
- Normal:
  `time PYTHONPATH=services/ingestor/src uv run python -c "from ingestor.cli import main; raise SystemExit(main(['--input','data/perf/events_1m.csv','--output','/tmp/events_normal.jsonl','--max-errors','1']))"`
- Compact:
  `time PYTHONPATH=services/ingestor/src uv run python -c "from ingestor.cli import main; raise SystemExit(main(['--input','data/perf/events_1m.csv','--output','/tmp/events_compact.jsonl','--max-errors','1','--compact-json']))"`

Results:
- Normal total: 5.854s
- Compact total: 5.840s
- File sizes:
  - normal: 138M
  - compact: 126M

Conclusion:
- Compact JSON reduces output size significantly (~9%) but has no meaningful impact on runtime on this machine (difference is within noise).
